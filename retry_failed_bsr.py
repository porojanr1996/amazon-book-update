#!/usr/bin/env python3
"""
Script pentru a identifica cÄƒrÈ›ile care au eÈ™uat la update BSR din log-uri
È™i a re-porneÈ™te update-ul doar pentru acele cÄƒrÈ›i
"""
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from google_sheets_transposed import GoogleSheetsManager
from amazon_scraper import AmazonScraper
import config

def extract_failed_books_from_logs(log_file_path="app.log", max_lines=10000):
    """
    Extrage cÄƒrÈ›ile care au eÈ™uat din log-uri
    
    ReturneazÄƒ: dict cu {worksheet_name: [list of amazon_urls]}
    """
    failed_books = {}  # {worksheet: [urls]}
    current_worksheet = None
    current_book_url = None
    
    print("ğŸ“‹ Analizare log-uri pentru cÄƒrÈ›i eÈ™uate...")
    print()
    
    try:
        with open(log_file_path, 'r', encoding='utf-8') as f:
            # CiteÈ™te ultimele max_lines linii
            lines = f.readlines()[-max_lines:]
            
            for line in lines:
                # IdentificÄƒ worksheet-ul curent
                worksheet_match = re.search(r'Procesare:\s*(.+?)$', line)
                if worksheet_match:
                    current_worksheet = worksheet_match.group(1).strip()
                    if current_worksheet not in failed_books:
                        failed_books[current_worksheet] = []
                
                # IdentificÄƒ URL-ul cÄƒrÈ›ii curente
                url_match = re.search(r'URL:\s*(https?://[^\s]+)', line)
                if url_match:
                    current_book_url = url_match.group(1).strip()
                
                # IdentificÄƒ eÈ™ecuri
                if re.search(r'âŒ Nu s-a putut extrage BSR|Failed to scrape BSR|BSR not found|Request error', line, re.IGNORECASE):
                    if current_worksheet and current_book_url:
                        # AdaugÄƒ URL-ul dacÄƒ nu existÄƒ deja
                        if current_book_url not in failed_books.get(current_worksheet, []):
                            failed_books.setdefault(current_worksheet, []).append(current_book_url)
                            print(f"   âŒ EÈ™ec gÄƒsit: {current_worksheet} - {current_book_url}")
    
    except FileNotFoundError:
        print(f"âš ï¸  FiÈ™ierul de log nu a fost gÄƒsit: {log_file_path}")
        return {}
    except Exception as e:
        print(f"âŒ Eroare la citirea log-urilor: {e}")
        return {}
    
    print()
    return failed_books

def get_books_by_urls(sheets_manager, worksheet_name, urls):
    """ObÈ›ine cÄƒrÈ›ile din Google Sheets care au URL-urile specificate"""
    all_books = sheets_manager.get_all_books(worksheet_name)
    matching_books = []
    
    for book in all_books:
        book_url = book.get('amazon_link', '').strip()
        # NormalizeazÄƒ URL-urile pentru comparaÈ›ie
        for url in urls:
            url_normalized = url.strip()
            # ComparÄƒ URL-urile (poate fi cu sau fÄƒrÄƒ trailing slash, query params, etc.)
            if url_normalized in book_url or book_url in url_normalized:
                matching_books.append(book)
                break
    
    return matching_books

def retry_failed_books(failed_books_dict, dry_run=False):
    """
    Re-Ã®ncearcÄƒ update-ul BSR pentru cÄƒrÈ›ile care au eÈ™uat
    
    Args:
        failed_books_dict: {worksheet_name: [list of amazon_urls]}
        dry_run: DacÄƒ True, nu scrie Ã®n Google Sheets
    """
    if not failed_books_dict:
        print("âœ… Nu s-au gÄƒsit cÄƒrÈ›i eÈ™uate Ã®n log-uri!")
        return True
    
    print("=" * 60)
    print("ğŸ”„ RE-ÃNCERCARE UPDATE BSR PENTRU CÄ‚RÈšI EÈ˜UATE")
    print("=" * 60)
    print()
    
    if dry_run:
        print("âš ï¸  MOD DRY-RUN: Nu se vor scrie date Ã®n Google Sheets")
        print()
    
    # Conectare la Google Sheets
    print("ğŸ“‹ Conectare la Google Sheets...")
    try:
        sheets_manager = GoogleSheetsManager(
            config.GOOGLE_SHEETS_CREDENTIALS_PATH,
            config.GOOGLE_SHEETS_SPREADSHEET_ID
        )
        print("âœ… Conectat cu succes")
    except Exception as e:
        print(f"âŒ Eroare la conectare: {e}")
        return False
    print()
    
    # IniÈ›ializare scraper
    scraper = AmazonScraper(
        delay_between_requests=config.AMAZON_DELAY_BETWEEN_REQUESTS,
        retry_attempts=config.AMAZON_RETRY_ATTEMPTS
    )
    
    total_success = 0
    total_failed = 0
    
    # ProceseazÄƒ fiecare worksheet
    for worksheet_name, failed_urls in failed_books_dict.items():
        print(f"ğŸ“š Worksheet: {worksheet_name}")
        print(f"   ğŸ“– CÄƒrÈ›i eÈ™uate: {len(failed_urls)}")
        print("-" * 60)
        
        # ObÈ›ine cÄƒrÈ›ile care au eÈ™uat
        failed_books = get_books_by_urls(sheets_manager, worksheet_name, failed_urls)
        
        if not failed_books:
            print(f"   âš ï¸  Nu s-au gÄƒsit cÄƒrÈ›i Ã®n Google Sheets pentru URL-urile eÈ™uate")
            print()
            continue
        
        print(f"   ğŸ“– GÄƒsite {len(failed_books)} cÄƒrÈ›i pentru re-Ã®ncercare")
        print()
        
        # ObÈ›ine rÃ¢ndul pentru astÄƒzi
        today_row = sheets_manager.get_today_row(worksheet_name)
        print(f"   ğŸ“… RÃ¢nd pentru astÄƒzi: {today_row}")
        print()
        
        worksheet_success = 0
        worksheet_failed = 0
        
        # ProceseazÄƒ fiecare carte eÈ™uatÄƒ
        for i, book in enumerate(failed_books, 1):
            print(f"   ğŸ“– [{i}/{len(failed_books)}] {book['name']}")
            print(f"      ğŸ‘¤ Autor: {book['author']}")
            print(f"      ğŸ”— URL: {book['amazon_link']}")
            
            try:
                # Pentru UK, foloseÈ™te direct Playwright
                is_uk = '.co.uk' in book['amazon_link'] or 'amazon.co.uk' in book['amazon_link']
                
                if is_uk:
                    print(f"      ğŸ” Re-Ã®ncercare cu Playwright (UK)...", end=' ', flush=True)
                    try:
                        bsr = scraper.extract_bsr(book['amazon_link'], use_playwright=True)
                    except Exception as e:
                        print(f"\n      âŒ Eroare Playwright: {e}")
                        bsr = None
                else:
                    # Pentru US, Ã®ncearcÄƒ mai Ã®ntÃ¢i cu requests
                    print(f"      ğŸ” Re-Ã®ncercare extragere BSR...", end=' ', flush=True)
                    bsr = scraper.extract_bsr(book['amazon_link'], use_playwright=False)
                    
                    # DacÄƒ nu funcÈ›ioneazÄƒ, Ã®ncearcÄƒ cu Playwright
                    if not bsr:
                        print(f"\n      ğŸ”„ Ãncercare cu Playwright...", end=' ', flush=True)
                        bsr = scraper.extract_bsr(book['amazon_link'], use_playwright=True)
                
                if bsr:
                    print(f"âœ… BSR: #{bsr:,}")
                    
                    if not dry_run:
                        # Scrie Ã®n Google Sheets
                        sheets_manager.update_bsr(book['col'], today_row, bsr, worksheet_name)
                        print(f"      âœ… Scris Ã®n Google Sheets (coloana {book['col']}, rÃ¢ndul {today_row})")
                    else:
                        print(f"      âš ï¸  DRY-RUN: Ar fi scris BSR #{bsr:,}")
                    
                    worksheet_success += 1
                    total_success += 1
                else:
                    print(f"âŒ Nu s-a putut extrage BSR (din nou)")
                    worksheet_failed += 1
                    total_failed += 1
            
            except Exception as e:
                print(f"âŒ Eroare: {e}")
                worksheet_failed += 1
                total_failed += 1
            
            print()
            
            # Delay Ã®ntre request-uri
            if i < len(failed_books):
                delay = config.AMAZON_DELAY_BETWEEN_REQUESTS
                print(f"      â³ AÈ™teptare {delay}s Ã®ntre request-uri...")
                time.sleep(delay)
                print()
        
        # Rezumat pentru worksheet
        print(f"   ğŸ“Š Rezumat {worksheet_name}:")
        print(f"      âœ… Succese: {worksheet_success}")
        print(f"      âŒ EÈ™ecuri: {worksheet_failed}")
        print()
        
        # CalculeazÄƒ È™i actualizeazÄƒ media (dacÄƒ nu e dry-run)
        if not dry_run and worksheet_success > 0:
            try:
                print(f"   ğŸ“Š Recalculare medie BSR pentru {worksheet_name}...")
                sheets_manager.calculate_and_update_average(today_row, worksheet_name)
                print(f"   âœ… Medie actualizatÄƒ")
            except Exception as e:
                print(f"   âš ï¸  Eroare la calcularea mediei: {e}")
            print()
    
    # Rezumat final
    print("=" * 60)
    print("ğŸ“Š REZUMAT FINAL RE-ÃNCERCARE")
    print("=" * 60)
    print(f"   âœ… Succese: {total_success}")
    print(f"   âŒ EÈ™ecuri: {total_failed}")
    print(f"   ğŸ“š Total procesate: {total_success + total_failed}")
    print()
    
    return total_failed == 0

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Re-Ã®ncearcÄƒ update BSR pentru cÄƒrÈ›ile eÈ™uate')
    parser.add_argument('--log-file', '-l', default='app.log',
                       help='Calea cÄƒtre fiÈ™ierul de log (default: app.log)')
    parser.add_argument('--dry-run', action='store_true',
                       help='Mod dry-run: nu scrie Ã®n Google Sheets')
    parser.add_argument('--max-lines', type=int, default=10000,
                       help='NumÄƒrul maxim de linii de log de analizat (default: 10000)')
    
    args = parser.parse_args()
    
    print()
    if args.dry_run:
        print("âš ï¸  ATENÈšIE: Mod DRY-RUN activat - nu se vor scrie date!")
    else:
        print("âš ï¸  ATENÈšIE: Acest script va scrie date reale Ã®n Google Sheets!")
    print()
    
    # Extrage cÄƒrÈ›ile eÈ™uate din log-uri
    failed_books = extract_failed_books_from_logs(args.log_file, args.max_lines)
    
    if not failed_books:
        print("âœ… Nu s-au gÄƒsit cÄƒrÈ›i eÈ™uate Ã®n log-uri!")
        sys.exit(0)
    
    print(f"ğŸ“Š GÄƒsite cÄƒrÈ›i eÈ™uate Ã®n {len(failed_books)} worksheet-uri:")
    for ws, urls in failed_books.items():
        print(f"   - {ws}: {len(urls)} cÄƒrÈ›i")
    print()
    
    if not args.dry_run:
        response = input("ContinuÄƒ cu re-Ã®ncercarea? (da/nu): ").strip().lower()
        if response not in ['da', 'yes', 'y', 'd']:
            print("âŒ Anulat.")
            sys.exit(0)
        print()
    
    # Re-Ã®ncearcÄƒ update-ul
    success = retry_failed_books(failed_books, dry_run=args.dry_run)
    sys.exit(0 if success else 1)

